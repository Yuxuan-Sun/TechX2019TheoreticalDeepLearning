{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(8)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "dtype = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9805824/9912422 [00:24<00:00, 509413.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:01<00:00, 63300.34it/s]\u001b[A\n",
      "32768it [00:01, 29928.45it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:29, 55319.94it/s]\u001b[A\n",
      "  3%|▎         | 49152/1648877 [00:01<00:23, 66705.22it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:01<00:18, 83145.55it/s]\u001b[A\n",
      "  9%|▉         | 155648/1648877 [00:01<00:15, 97672.49it/s]\u001b[A\n",
      " 13%|█▎        | 221184/1648877 [00:02<00:12, 114859.96it/s]\u001b[A\n",
      " 17%|█▋        | 278528/1648877 [00:02<00:10, 134933.97it/s]\u001b[A\n",
      " 21%|██▏       | 352256/1648877 [00:02<00:08, 160295.04it/s]\u001b[A\n",
      " 25%|██▌       | 417792/1648877 [00:02<00:06, 182064.88it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:03<00:06, 188062.86it/s]\u001b[A\n",
      " 35%|███▍      | 573440/1648877 [00:03<00:05, 199539.88it/s]\u001b[A\n",
      " 39%|███▉      | 647168/1648877 [00:03<00:04, 219910.92it/s]\u001b[A\n",
      " 45%|████▍     | 737280/1648877 [00:04<00:03, 246370.29it/s]\u001b[A\n",
      " 50%|████▉     | 819200/1648877 [00:04<00:02, 310849.44it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:04<00:02, 308544.45it/s]\u001b[A\n",
      " 56%|█████▌    | 917504/1648877 [00:04<00:02, 268782.53it/s]\u001b[A\n",
      " 61%|██████    | 1007616/1648877 [00:04<00:01, 334694.15it/s]\u001b[A\n",
      " 64%|██████▍   | 1056768/1648877 [00:04<00:01, 315189.00it/s]\u001b[A\n",
      " 68%|██████▊   | 1122304/1648877 [00:05<00:01, 298558.45it/s]\u001b[A\n",
      " 75%|███████▍  | 1228800/1648877 [00:05<00:01, 321032.15it/s]\u001b[A\n",
      " 81%|████████▏ | 1343488/1648877 [00:05<00:00, 349828.26it/s]\u001b[A\n",
      " 88%|████████▊ | 1458176/1648877 [00:05<00:00, 376610.18it/s]\u001b[A\n",
      " 95%|█████████▌| 1572864/1648877 [00:06<00:00, 432413.00it/s]\u001b[A\n",
      " 98%|█████████▊| 1622016/1648877 [00:06<00:00, 405815.73it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 15608.03it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Build and transform the dataset\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "trains = datasets.MNIST('./data', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            ((0.1307,), (0.3081,)),\n",
    "                        ]))\n",
    "tests = datasets.MNIST('./data', train=False,\n",
    "                       transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                        ]))\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(trains, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(tests, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "train_data = [x.view(28*28, -1).numpy() for x in trains.train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_labels = trains.train_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    dx = sigmoid(x)\n",
    "    return dx * (1.0 - dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(object):\n",
    "    \"\"\"The fully connected neural network\"\"\"\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(x, y) for x, y in zip(sizes[1:], sizes[:-1])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Feedforward to compute loss\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Backpropagate to compute gradients\"\"\"\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activations = []\n",
    "        # the input will act as the activation of the weight in the first layer\n",
    "        activations.append(x)\n",
    "        zs = []\n",
    "        l = 0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activations[l]) + b\n",
    "            zs.append(z)\n",
    "            activations.append(sigmoid(z))\n",
    "            l = l + 1\n",
    "        delta = (activations[-1] - y) * (sigmoid_prime(zs[-1]))\n",
    "        grad_b[-1] = delta\n",
    "        grad_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        for l in range(2, self.num_layers):\n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * sigmoid_prime(zs[-l])\n",
    "            grad_b[-l] = delta\n",
    "            grad_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
    "        return zip(grad_b, grad_w)\n",
    "\n",
    "    def update(self, data, lr):\n",
    "        \"\"\"Update weights and biases with gradients derived by backpropagation\"\"\"\n",
    "        grad_b_sum = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w_sum = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in data:\n",
    "            l = 0\n",
    "            for grad_b, grad_w in self.backprop(x, y):\n",
    "                grad_b_sum[l] = grad_b_sum[l] + grad_b\n",
    "                grad_w_sum[l] = grad_w_sum[l] + grad_w\n",
    "                l = l + 1\n",
    "        self.biases = [b - lr / len(data) * grad_b for b, grad_b in zip(self.biases, grad_b_sum)]\n",
    "        self.weights = [w - lr / len(data) * grad_w for w, grad_w in zip(self.weights, grad_w_sum)]\n",
    "\n",
    "    def grad_descent(self, dataloader, lr):\n",
    "        \"\"\"Batch gradient descent algorithm\"\"\"\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            x_list = [image.view(28*28, -1).numpy() for image in images]\n",
    "            y_list = []\n",
    "            for y_value in labels.numpy():\n",
    "                y = np.zeros((10, 1))\n",
    "                y[y_value] = 1.0\n",
    "                y_list.append(y)\n",
    "            data = list(zip(x_list, y_list))\n",
    "            self.update(data, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py\", line 95, in __getitem__\n    img = self.transform(img)\n  File \"/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\nTypeError: 'tuple' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-69ab60951805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a453d683a670>\u001b[0m in \u001b[0;36mgrad_descent\u001b[0;34m(self, dataloader, lr)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;34m\"\"\"Batch gradient descent algorithm\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0my_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py\", line 95, in __getitem__\n    img = self.transform(img)\n  File \"/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\nTypeError: 'tuple' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:40, 509413.19it/s]                             \n",
      "1654784it [00:23, 405815.73it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "test_data = list(zip(train_data, train_labels))\n",
    "fnn = FNN([784, 30, 10])\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    fnn.grad_descent(train_loader, 3)\n",
    "    count = 0\n",
    "    for (x, y) in test_data:\n",
    "        if np.argmax(fnn.feedforward(x)) == y:\n",
    "            count = count + 1\n",
    "    print('Epochs {}: {}% time: {}s'.format(epoch + 1, format(count / len(test_data) * 100.0, '.2f'), time.time() - epoch_start_time))\n",
    "print('total time cost: {}s'.format(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
